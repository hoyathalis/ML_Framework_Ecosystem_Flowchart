<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML/AI Framework Ecosystem: From Code to Hardware</title>
    <style>
        body {
            margin: 0;
            padding: 20px;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            line-height: 1.6;
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background-color: white;
            padding: 40px;
            border-radius: 16px;
            box-shadow: 0 8px 32px rgba(0,0,0,0.1);
        }
        .header {
            text-align: center;
            margin-bottom: 40px;
        }
        h1 {
            color: #2c3e50;
            margin-bottom: 15px;
            font-size: 2.5em;
            font-weight: 700;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        .subtitle {
            font-size: 1.2em;
            color: #666;
            margin-bottom: 20px;
        }
        .description {
            font-size: 1.1em;
            color: #555;
            max-width: 800px;
            margin: 0 auto;
            text-align: center;
        }
        .chart-controls {
            text-align: center;
            margin: 20px 0;
        }
        .toggle-btn {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 25px;
            font-size: 1em;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
        }
        .toggle-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
        }
        .chart-note {
            margin: 10px 0 0 0;
            color: #666;
            font-size: 0.9em;
        }
        .chart-container {
            width: 100%;
            min-height: 700px;
            border: 2px solid #e0e6ed;
            border-radius: 12px;
            overflow: hidden;
            margin: 20px 0 40px 0;
            box-shadow: 0 4px 20px rgba(0,0,0,0.08);
            background: white;
        }
        .chart-container iframe {
            width: 100%;
            height: 700px;
        }
        .mermaid {
            padding: 20px;
            background: white;
            min-height: 600px;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .content-section {
            margin: 40px 0;
            padding: 30px;
            background: #f8fafc;
            border-radius: 12px;
            border-left: 4px solid #667eea;
        }
        .section-title {
            font-size: 1.5em;
            color: #2c3e50;
            margin-bottom: 20px;
            font-weight: 600;
        }
        .layer {
            margin: 25px 0;
            padding: 20px;
            background: white;
            border-radius: 8px;
            border: 1px solid #e0e6ed;
        }
        .layer-title {
            font-weight: 600;
            color: #667eea;
            margin-bottom: 10px;
            font-size: 1.1em;
        }
        .layer-description {
            color: #666;
            margin-bottom: 10px;
        }
        .layer-examples {
            font-style: italic;
            color: #888;
            font-size: 0.95em;
        }
        .insights-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }
        .insight-card {
            background: white;
            padding: 20px;
            border-radius: 8px;
            border: 1px solid #e0e6ed;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        }
        .insight-title {
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 10px;
        }
        .footer {
            text-align: center;
            margin-top: 50px;
            padding-top: 30px;
            border-top: 1px solid #e0e6ed;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ML/AI Framework Ecosystem Flowchart</h1>
            <p class="subtitle">Understanding the Complete Journey from High-Level Code to Hardware Execution</p>
            <p class="description">
                Explore how machine learning frameworks transform your Python code into optimized instructions 
                that run efficiently on diverse hardware platforms including CPUs, GPUs, TPUs, and specialized AI chips.
            </p>
        </div>

        <div class="chart-controls">
            <button id="toggleChart" class="toggle-btn">Switch to Mermaid View</button>
            <p class="chart-note">Having trouble with the interactive chart? Try the alternative view above.</p>
        </div>

        <div id="iframeChart" class="chart-container">
            <iframe src="https://claude.site/public/artifacts/e44d47cf-35c2-4d48-8046-8b801680b465/embed" 
                    title="ML/AI Framework Ecosystem Interactive Flowchart" 
                    width="100%" 
                    height="700" 
                    frameborder="0" 
                    allow="clipboard-write" 
                    allowfullscreen>
            </iframe>
        </div>

        <div id="mermaidChart" class="chart-container" style="display: none;">
            <div class="mermaid">
flowchart TD
  %% Layer 1: Frameworks
  subgraph L1["ðŸŽ¯ Layer 1: High-Level Frameworks"]
    direction TB
    PT["ðŸ”¥ PyTorch<br/>nn.Module"]
    TF["ðŸŸ  TensorFlow<br/>Graph/Eager"]
    JAX["ðŸ”µ JAX<br/>NumPy-style"]
  end

  %% Layer 2: Bridges / Frontends
  subgraph L2["ðŸ”— Layer 2: Bridges / Frontends"]
    direction TB
    subgraph L2A["PyTorch Bridges"]
      direction TB
      TC["ðŸ“¦ torch.compile"]
      PXLA["ðŸ“¦ torch_xla"]
      TMLIR["ðŸ“¦ torch-mlir"]
      PTONNX["ðŸ“¦ torch.onnx"]
    end
    subgraph L2B["TensorFlow Bridges"]
      direction TB
      TFXLA["ðŸ“¦ tf.function (+XLA)"]
      TFMLIR["ðŸ“¦ TF-MLIR"]
      TF2TFL["ðŸ“¦ TFLite Converter (TF)"]
      TFONNX["ðŸ“¦ tf2onnx"]
      TF2TRT["ðŸ“¦ TF-TensorRT"]
    end
    subgraph L2C["JAX Bridges"]
      direction TB
      JAXJIT["ðŸ“¦ jax.jit"]
      JAX2ONNX["ðŸ“¦ jax2onnx"]
    end
  end

  %% Layer 3: IRs & Exchange
  subgraph L3["ðŸ“‹ Layer 3: IRs & Exchange Formats"]
    direction TB
    FX["ðŸ“‹ FX Graph (PyTorch)"]
    STABLEHLO["ðŸ“¦ StableHLO (OpenXLA)"]
    MLIR["ðŸ—ï¸ MLIR (TOSA/Linalg/etc.)"]
    ONNX["ðŸ“¦ ONNX (Exchange)"]
  end

  %% Converters
  subgraph L3C["ðŸ”„ Converters"]
    direction TB
    ONNXTFL["ONNX â†’ TFLite"]
    ONNX2TRT["ONNX â†’ TensorRT"]
    ONNX2COREML["ONNX â†’ Core ML"]
    TORCHTRT["Torch-TensorRT"]
  end

  %% Layer 4: Compilers & Runtimes
  subgraph L4["âš¡ Layer 4: Compilers & Runtimes"]
    direction TB
    IND["ðŸ”§ TorchInductor"]
    XLA["âš¡ OpenXLA (XLA)"]
    TVM["ðŸŽ¯ TVM"]
    IREE["ðŸ“¦ IREE"]
    TRITON["ðŸ”º Triton Kernels"]
    ORT["â–¶ï¸ ONNX Runtime"]
    TFLITE["â–¶ï¸ TFLite Interpreter"]
    TRT["â–¶ï¸ TensorRT Engine"]
    COREMLRT["â–¶ï¸ Core ML Runtime"]
    NNAPIRT["â–¶ï¸ NNAPI Runtime"]
  end

  %% Layer 5: Hardware
  subgraph L5["ðŸ–¥ï¸ Layer 5: Hardware Targets"]
    direction TB
    CPU["ðŸ’» CPU"]
    GPU["ðŸŽ® GPU"]
    TPU["ðŸ§  TPU"]
    DSP["ðŸ“¶ DSP/Hexagon"]
    ANE["ðŸŽ Apple Neural Engine"]
    NPU["ðŸ“± Mobile NPU"]
  end

  %% Ordering
  L1 --> L2 --> L3 --> L3C --> L4 --> L5

  %% PyTorch
  PT --> TC --> FX --> IND
  PT --> PXLA --> STABLEHLO
  PT --> TMLIR --> MLIR
  PT --> PTONNX --> ONNX
  PT -.-> TORCHTRT

  %% TensorFlow
  TF --> TFXLA --> STABLEHLO
  TF --> TFMLIR --> MLIR
  TF --> TF2TFL --> TFLITE
  TF --> TFONNX --> ONNX
  TF --> TF2TRT --> TRT

  %% JAX
  JAX --> JAXJIT --> STABLEHLO
  JAX --> JAX2ONNX --> ONNX

  %% IRs
  STABLEHLO --> XLA
  MLIR --> IREE
  ONNX --> TVM
  ONNX --> ORT
  %% optional via onnx-mlir
  ONNX -.-> MLIR

  %% Converters
  ONNX --> ONNXTFL --> TFLITE
  ONNX --> ONNX2TRT --> TRT
  ONNX --> ONNX2COREML --> COREMLRT
  TORCHTRT --> TRT

  %% Compilers/Runtimes
  IND --> TRITON --> GPU
  IND --> CPU
  XLA --> TPU
  XLA --> GPU
  XLA --> CPU
  IREE --> CPU
  IREE --> GPU
  IREE --> NNAPIRT
  TVM --> CPU
  TVM --> GPU
  TVM -.-> NNAPIRT

  ORT --> CPU
  ORT --> GPU
  ORT --> NNAPIRT
  ORT --> COREMLRT

  TFLITE --> CPU
  TFLITE --> GPU
  TFLITE --> NNAPIRT
  TFLITE --> DSP
  TFLITE --> COREMLRT

  TRT --> GPU
  COREMLRT --> ANE
  COREMLRT --> GPU
  COREMLRT --> CPU
  NNAPIRT --> NPU
  NNAPIRT --> CPU

  %% Styling
  classDef layer fill:#f8f9fa,stroke:#343a40,stroke-width:3px
  classDef framework fill:#e1f5fe,stroke:#0277bd,color:#000
  classDef ir fill:#fff8e1,stroke:#ff8f00,color:#000
  classDef converter fill:#fff3e0,stroke:#f57c00,color:#000
  classDef compiler fill:#e8eaf6,stroke:#3f51b5,color:#000
  classDef runtime fill:#ede7f6,stroke:#5e35b1,color:#000
  classDef hardware fill:#e8f5e8,stroke:#2e7d32,color:#000

  class L1,L2,L3,L3C,L4,L5 layer
  class PT,TF,JAX framework
  class FX,ONNX,STABLEHLO,MLIR ir
  class ONNXTFL,ONNX2TRT,ONNX2COREML,TORCHTRT converter
  class IND,XLA,TVM,IREE,TRITON compiler
  class ORT,TFLITE,TRT,COREMLRT,NNAPIRT runtime
  class CPU,GPU,TPU,DSP,ANE,NPU hardware
            </div>
        </div>

        <div class="content-section">
            <h2 class="section-title">Understanding the 5-Layer Architecture</h2>
            
            <div class="layer">
                <div class="layer-title">Layer 1: High-Level Frameworks</div>
                <div class="layer-description">
                    The entry point where developers write machine learning code using familiar Python APIs.
                </div>
                <div class="layer-examples">
                    Examples: PyTorch (nn.Module), TensorFlow (Graph/Eager), JAX (NumPy-style)
                </div>
            </div>

            <div class="layer">
                <div class="layer-title">Layer 2: Bridges & Frontends</div>
                <div class="layer-description">
                    Translation tools that convert framework-specific code into intermediate formats for optimization.
                </div>
                <div class="layer-examples">
                    Examples: torch.compile, tf.function, jax.jit - enabling cross-platform compatibility
                </div>
            </div>

            <div class="layer">
                <div class="layer-title">Layer 3: Intermediate Representations (IRs)</div>
                <div class="layer-description">
                    Universal formats that standardize model representation across different tools and platforms.
                </div>
                <div class="layer-examples">
                    Examples: ONNX (universal exchange), StableHLO (OpenXLA), MLIR (multi-level IR), FX Graph (PyTorch internal)
                </div>
            </div>

            <div class="layer">
                <div class="layer-title">Layer 4: Compilers & Runtimes</div>
                <div class="layer-description">
                    Sophisticated systems that transform IRs into optimized, hardware-specific executable code.
                </div>
                <div class="layer-examples">
                    Compilers: TorchInductor, XLA, TVM, IREE, Triton | Runtimes: ONNX Runtime, TensorRT, TFLite, Core ML
                </div>
            </div>

            <div class="layer">
                <div class="layer-title">Layer 5: Hardware Targets</div>
                <div class="layer-description">
                    The final destination where optimized code executes on diverse computing platforms.
                </div>
                <div class="layer-examples">
                    Examples: CPUs, GPUs, TPUs, Mobile NPUs, Apple Neural Engine, DSP chips
                </div>
            </div>
        </div>

        <div class="content-section">
            <h2 class="section-title">Key Insights</h2>
            <div class="insights-grid">
                <div class="insight-card">
                    <div class="insight-title">Multiple Pathways</div>
                    <div>Each framework can reach the same hardware through different compilation paths, offering flexibility in optimization strategies.</div>
                </div>
                <div class="insight-card">
                    <div class="insight-title">ONNX as Universal Bridge</div>
                    <div>ONNX serves as a critical interchange format, enabling models trained in one framework to run on runtimes optimized for different deployment scenarios.</div>
                </div>
                <div class="insight-card">
                    <div class="insight-title">Hardware Specialization</div>
                    <div>Different hardware targets (mobile, server, edge) have specialized runtimes and optimization paths tailored to their constraints.</div>
                </div>
                <div class="insight-card">
                    <div class="insight-title">Ecosystem Complexity</div>
                    <div>The modern ML deployment landscape involves numerous intermediate steps and format conversions, reflecting the diversity of hardware targets and optimization requirements.</div>
                </div>
            </div>
        </div>

        <div class="footer">
            <p>This architecture enables developers to write code in familiar high-level frameworks while achieving optimized performance across diverse hardware platforms.</p>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.6.1/dist/mermaid.min.js"></script>
    <script>
        mermaid.initialize({ 
            startOnLoad: true,
            theme: 'default',
            flowchart: {
                useMaxWidth: true,
                htmlLabels: true
            }
        });

        let isIframeView = true;
        const toggleBtn = document.getElementById('toggleChart');
        const iframeChart = document.getElementById('iframeChart');
        const mermaidChart = document.getElementById('mermaidChart');

        toggleBtn.addEventListener('click', function() {
            if (isIframeView) {
                // Switch to Mermaid view
                iframeChart.style.display = 'none';
                mermaidChart.style.display = 'block';
                toggleBtn.textContent = 'Switch to Interactive View';
                isIframeView = false;
            } else {
                // Switch to iframe view
                iframeChart.style.display = 'block';
                mermaidChart.style.display = 'none';
                toggleBtn.textContent = 'Switch to Mermaid View';
                isIframeView = true;
            }
        });

        // Error handling for iframe loading
        const iframe = document.querySelector('iframe');
        iframe.addEventListener('error', function() {
            console.log('Iframe failed to load, switching to Mermaid view');
            toggleBtn.click();
        });

        // Check if iframe loads successfully after a timeout
        setTimeout(function() {
            try {
                if (iframe.contentDocument || iframe.contentWindow.document) {
                    // Iframe loaded successfully
                } else {
                    // Iframe might be blocked, offer alternative
                    document.querySelector('.chart-note').innerHTML = 
                        '<strong>Interactive chart blocked?</strong> Click the button above to view the Mermaid version.';
                }
            } catch (e) {
                // Cross-origin or other error
                console.log('Iframe access error:', e);
            }
        }, 3000);
    </script>
</body>
</html>